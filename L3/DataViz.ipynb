{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4998a43b-366f-4def-9803-4a6d22d3fd66",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this lecture we will learn about different methods for visualizing data, and the exploratory data analysis (EDA) that you can do purely with visual techniques. Some specific topics we will cover:\n",
    "- Basic plotting with matplotlib and seaborn: scatter plots, histograms, box plots, time series\n",
    "- Exploratory Data Analysis\n",
    "- Parameter settings & $\\LaTeX$ rendering for publication-quality plots\n",
    "- Multi-panel plots\n",
    "- 2D heatmaps\n",
    "- 3D surface plots\n",
    "- Saving videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deefefb-4a83-4fa9-a9d7-aec5d843aa65",
   "metadata": {},
   "source": [
    "# The Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63552cb-74a6-42b6-9eb5-cab7c8c9f965",
   "metadata": {},
   "source": [
    "## Scatter plots\n",
    "One of the most common plots you will make as a data scientist is a scatter plot, which helps you determine whether two variables are related to each other. In other words: as the value of one variable increases, does the value of the other variable also increase? Or does it decrease? Or remain approximately constant? We can generate some random data to explore this technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805db6e-0668-4c04-8b46-89cf0ca5311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # Matplotlib is the standard plotting package, and this is the standard way to import it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ccb171-583d-424f-98ef-490cc196bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)  # 100 values linearly spaced between -10 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85d274-32bb-492e-9e01-d76191ca8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff6622-8dc7-4cdb-97a4-86ad8c4fd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.randn(len(x)) * 2  # Normally distributed random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d5456-3dfb-47fb-a046-2510871883b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1.5 * x + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af132166-c734-47b8-b84b-a69585078f16",
   "metadata": {},
   "source": [
    "We have now defined two arrays, `x` and `y` that are the same size (100 elements each). We can create an x vs y scatter plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d22902-5cf2-4a26-baab-f67458e677c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053476ab-aa8e-4080-ae6a-4060d833fff9",
   "metadata": {},
   "source": [
    "Or equivalently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90cefb-cb28-448a-8868-8cf9f9fce5ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52de4d-862d-4349-8dc5-05b6e60c1d54",
   "metadata": {},
   "source": [
    "But if you turned in a plot like this for your homework, you would lose many points. Let's add some key elements, like labels. This would be the bare minimum required for an acceptable plot; we'll learn later about ways to make publication-quality graphics in matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6bae5-f358-4611-be5a-e70795e8e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'o')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Example Scatter Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d65ae84-3953-41cd-a057-f3dad6431991",
   "metadata": {},
   "source": [
    "Seems pretty clear that `x` and `y` are positively correlated to each other. But what about `x` and `noise`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4b2f0-c7fb-4d06-a089-936061ea3ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x, noise, 'o')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Gaussian Noise\")\n",
    "plt.title(\"Example Scatter Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d03d9b-98c4-4aa7-bb52-374d9bce09bb",
   "metadata": {},
   "source": [
    "Not so much. Even without calculating any statistics, we can see visually that the two variables don't have a relationship to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e9ef1-9c82-47f1-b8ec-0a2f98a1bc9d",
   "metadata": {},
   "source": [
    "But what if we wanted to quantify the level of correlation between the variables? For that, we can calculate the correlation coefficient:\n",
    "$$ \\rho_{xy} = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\overline{x})^2}\\sqrt{\\sum_{i=1}^n(y_i - \\overline{y})^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d965fa-8735-49ef-9966-46d1d7596857",
   "metadata": {},
   "source": [
    "The numpy function `corrcoef` calculates a 2x2 correlation matrix, with the correlation between $x$ and $x$ along the diagonal, and the correlations between $x$ and $y$ and $y$ and $x$ as the off-diagonal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50fc1a-dd8f-413b-8dae-74caf3ba8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(x, y)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43a57b-8610-43d7-949e-6e037b2b1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_xy = corr[0, 1] # extract from row 0, column 1\n",
    "rho_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c58697-cefe-4c54-9aaa-1bb5d79fc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.corrcoef(x, noise)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9fd36-3dab-4003-8f86-41e41d92e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_xn = corr[0, 1]\n",
    "rho_xn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9474f-d6cd-48fc-80f5-746291cf8d40",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "Sometimes we only have one variable to look at rather than two variables to compare to each other. In this case, a histogram is a good visualization tool. As a reminder: histograms split your variable up into intervals/ranges/bins of values, and then count how many values fall into each bin. The bins will be on the x-axis, and the counts will be on the y-axis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ea2937-3b89-4677-b4ed-756377c872b9",
   "metadata": {},
   "source": [
    "### Plotting techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b620de5-f44d-4e9c-afb3-891b8ca42301",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(noise, bins=\"auto\")\n",
    "plt.xlabel(\"Noise Magnitude\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae656e9-6f6c-4472-8598-0508ff175b6d",
   "metadata": {},
   "source": [
    "Here, we used the optional argument `bins=\"auto\"` to tell matplotlib to automatically determine how many bins to use. We can manually specify this with an integer if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3c0cd-2a77-4506-93d2-3c2914103f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(noise, bins=3)\n",
    "plt.xlabel(\"Noise Magnitude\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbef22-8a27-4901-9338-1d7144db0c3f",
   "metadata": {},
   "source": [
    "Or provide a range, which sets the boundary of each bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c45f7-19d3-4b96-84cc-2880840a79a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(noise, bins=np.arange(-5, 5, 0.1))\n",
    "plt.xlabel(\"Noise Magnitude\")\n",
    "plt.ylabel(\"Counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64108a-829b-4beb-9fe4-c50386533b05",
   "metadata": {},
   "source": [
    "As you can see, the histogram will look very different depending on how you bin it. A good histogram will give an accurate sense of the *distribution* of the data, e.g., unimodal vs bimodal, skewed vs symmetric. If you use too many bins, then most of the counts will be around 1. If you use too few bins, you'll just get a couple big bars. Something in between is what you want, and it can be more of an art than a science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba286c-fc93-4d8e-b28c-c340e11ed7ff",
   "metadata": {},
   "source": [
    "One more note about histograms: instead of having counts on the y-axis, we often have *density*, which is a way to normalize the histogram bar heights such that the area of all the bars (i.e., the area under the curve) sums to 1. This is helpful because it means that the probability of finding a sampling a certain range of values can be estimated as the area under the curve between those values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715f1ec-3f7e-4a33-a66f-bafcc4ed81be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(noise, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"Noise Magnitude\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d41ae-501e-4833-86d9-5b9db752fbd9",
   "metadata": {},
   "source": [
    "We can confirm that the area under the curve is equal to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c7563-bb5e-4641-8588-6c1f06ada4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "density, bins, _ = plt.hist(noise, bins=\"auto\", density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd624c67-59d6-4fd2-9884-2237f6bd30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = density\n",
    "dx = np.diff(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169dceb-4ca1-497c-8825-ddc34458c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y * dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157ae04-7f49-4e87-8c6a-65a466263c83",
   "metadata": {},
   "source": [
    "Another plotting package we will use is Seaborn. It has better integration with `pandas` than matplotlib, and it has nice built-in functionality to spruce up histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c720f5a-87de-482f-84de-12e46ff79827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0910a-7aef-4624-9b94-b80f0b14ccf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.histplot(x=noise, stat=\"density\", kde=True)\n",
    "ax.set_xlabel(\"Noise Magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb5a77-6d27-4e72-9cf1-fbee6ce051b8",
   "metadata": {},
   "source": [
    "In the plot above, the smooth line that we add using the `kde=True` option is the approximation of the underlying distribution that the histogram is sampled from. This is calculated using *kernel density estimation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0032c-4e21-4615-9ca1-72a66266ca49",
   "metadata": {},
   "source": [
    "### Histogram properties\n",
    "When we make a histogram of variable, the shape tells us a lot about which values of that variable are most common. I'll add made-up labels to the plot to give a more concrete idea of what they could represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261af466-b67f-4d44-9006-18bc59865903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, skewnorm, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12525110-97e7-4e16-a611-fd68be16c003",
   "metadata": {},
   "source": [
    "We would classify this histogram as *symmetric* and *unimodal*. The distribution is centered near `0`, which means it is the most likely (expected) value, and larger/smaller values get increasingly less common. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5aedb3-b662-43fb-b662-081c2d2f1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = norm.rvs(loc=0, scale=1, size=1000)\n",
    "ax = sns.histplot(x=values, stat=\"density\", kde=True)\n",
    "ax.set_xlabel(\"Forecast error in predicted wave height (m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32984375-234f-4dda-a783-6c87247ccf84",
   "metadata": {},
   "source": [
    "This histogram is *right-skewed* or *positive-skewed*. We would say that it has a long tail -- though they aren't very likely, large positive values do appear. Large negative values are extremely rare or impossible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fffc4-d1ae-4f15-998e-1cbaf123a165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = skewnorm.rvs(10, loc=0.5, scale=1, size=1000)\n",
    "ax = sns.histplot(x=values, stat=\"density\", kde=True)\n",
    "ax.set_xlabel(\"Daily total rainfall (in.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924d2a6-03b6-40d4-bb7d-070eb2e75a3d",
   "metadata": {},
   "source": [
    "Similarly, this one is *left-skewed* or *negative-skewed*. It has a long tail in the other direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcd868-8f01-489d-a4f0-f6cd4bcd21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = skewnorm.rvs(-3, loc=-1, scale=3, size=1000)\n",
    "ax = sns.histplot(x=values, stat=\"density\", kde=True)\n",
    "ax.set_xlabel(\"Actively-managed portfolio returns versus S&P 500 (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d0042e-0459-4ed6-b029-ba5e3eeac5c9",
   "metadata": {},
   "source": [
    "This distribution is *uniform*: any value within the range is equally likely to appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb26e0-7d0f-4830-816d-a1815172ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = uniform.rvs(loc=0, scale=1, size=1000)\n",
    "ax = sns.histplot(x=values, stat=\"density\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e8887-aa9b-4d50-b10a-1bf26eb71106",
   "metadata": {},
   "source": [
    "## Box plots\n",
    "If you want to compare the distributions of multiple variables to each other, one way to do it would be to make multiple histograms and stack them on top of each other. This can get a little messy though, so it is more common to rely on Box Plots. Let's see how they work with the Iris dataset and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e82b7-d491-4dfa-82e9-41d28a856a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291dd4c-53b4-4fc4-a4da-7ad8d3560c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"sepal_length\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd5c74-dcbb-4e7d-b947-7508af14ea14",
   "metadata": {},
   "source": [
    "Here, we told seaborn to plot data contained in the dataframe `df`. We wanted the `sepal_length` column, and we wanted a separate box plot for each unique value of `species`, denoted by the `hue` argument. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8b2c6-2010-4f51-9aa3-ebfca3c5f5db",
   "metadata": {},
   "source": [
    "But what is the box plot actually showing? Let's discuss the components of the diagram below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235785e9-4fbb-4fa2-85b9-ea22fa90e2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"boxplot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72e3e9f-8d22-4d05-9dfb-ea8071c71b44",
   "metadata": {},
   "source": [
    "## Breakout: Seaborn for Scatter Plots and Histograms\n",
    "1. Use Seaborn to make scatter plots of some of the different variables in the Iris dataset. Which variables are correlated to each other? How do these correlations change when your scatter plots are separated by species?\n",
    "2. Use Seaborn to make a single plot showing overlapping histograms for sepal length for the setosa and virginica species. How to the distributions of these variables differ from each other? How are they similar? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853769f3-919c-40c7-ad74-c8c5fdbbadf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ef586-383a-4dac-9f67-b58991add6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b89c40a0-55cc-4bd6-bcb6-50ca279ee936",
   "metadata": {},
   "source": [
    "## Time series data\n",
    "So far we haven't seen any data with a temporal (time) component. Any dataset where the sampling time is relevant is called time series data. This requires special handling in Python, as we will demonstrate with a sample air quality dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680787d1-ae4a-49e3-9152-7d990b17bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"air_quality_no2_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd6e02-f57a-45de-af0a-d179d194ce7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b160c3-d6aa-4c72-a840-22ae6ac80105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"city\"] == \"Paris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1ef4f-4f05-49b1-99f4-952a8d9fc508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06f10d-a206-47f5-89b1-c36b60726278",
   "metadata": {},
   "source": [
    "Let's say we want to plot the time (given by `date.utc`) vs the NO2 value (given by `value`). If we try to work with the data as it is read in, we run into trouble because the dates are interpreted as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17442e8f-be3e-47a4-b722-4c08eb7192ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"date.utc\"], df[\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b33bb-aa65-45f0-814b-5c72050f0781",
   "metadata": {},
   "source": [
    "We will almost always need to convert times into a pandas Datetime type before working with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886a35a-5de8-48ed-a8b7-26c5fecf2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date.utc\"] = pd.to_datetime(df[\"date.utc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f489fdb5-61fa-4a1d-b334-b9909043ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34dfa0-1422-403e-b160-043ed53b9834",
   "metadata": {},
   "source": [
    "Trying again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af045af6-9180-4814-b535-5987e5806c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"date.utc\"], df[\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ec354-a269-4659-b189-c9899c537c93",
   "metadata": {},
   "source": [
    "A little better, but still not great. Let's mess with some options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a07a7-71ff-4b3d-b6f9-16fdf91e26f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()  # Initialize a figure object\n",
    "plt.plot(df[\"date.utc\"], df[\"value\"])  # Make the plot\n",
    "plt.xticks(pd.date_range(start=\"2019-05-08\", end=\"2019-06-22\", freq=\"5D\"))  # Set the x-axis tick positions\n",
    "plt.ylabel(\"NO2 concentration\")\n",
    "plt.title(\"Paris Air Quality\")\n",
    "fig.autofmt_xdate()  # Rotates and offsets the x-axis labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ad2db-aee1-4062-b0e5-1096093b136c",
   "metadata": {},
   "source": [
    "# More Advanced Plotting\n",
    "The techniques above will give you a lot of mileage for exploratory data analysis, but for professional purposes you will want to give your plots a bit more pizzazz. Let's start by making plots look better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10d8dd-ff17-46e3-ac50-adc9229d5b11",
   "metadata": {},
   "source": [
    "## Plot params\n",
    "We can improve a simple plot dramatically by modifying the default parameters that matplotlib uses. Most of these are just related to the font style and size. By default it is hard to read the labels on a matplotlib plot unless it is on a computer screen in front of you. Remember that your audience may be squinting at the screen from across the room, and they need to be able to read your graphics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1310c4c-d4ec-497f-937f-4f988bd349c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"axes.labelsize\": 18, \n",
    "    \"font.size\": 18,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c42bcb-ff8d-4749-ad9c-34c3e9c1f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdate  # Package for formatting dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35de60-85b4-4114-9cdd-908caa116034",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # object-oriented figure initialization gives us more control over the options\n",
    "ax.plot(df[\"date.utc\"], df[\"value\"], linewidth=1.5, alpha=0.8)  # Slightly thicker line with a bit of transparency\n",
    "ax.set_xticks(pd.date_range(start=\"2019-05-08\", end=\"2019-06-22\", freq=\"5D\"))\n",
    "ax.set_ylabel(r\"NO$_2$ concentration ($\\mu$g/L)\")  # Format labels with LaTeX\n",
    "ax.set_title(\"Paris Air Quality, 2019\")\n",
    "ax.xaxis.set_major_formatter(mdate.DateFormatter(\"%m/%d\"))  # Custom x-tick label format\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 5)  # Optimal size will depend on the plot, but with time series you often want something pretty wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec869da2-ea98-4502-88fc-94d9acabc14e",
   "metadata": {},
   "source": [
    "## Multi-panel plots\n",
    "What if we want multiple subplots in a single figure? Matplotlib makes this easy. But I'm going to turn off TeX rendering because it's slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844dd251-b02a-49a0-be3d-23647d7edfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"axes.labelsize\": 18,\n",
    "    \"font.size\": 18,\n",
    "    \"legend.fontsize\": 16,\n",
    "    \"xtick.labelsize\": 18,\n",
    "    \"ytick.labelsize\": 18,\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": \"sans-serif\",  # sans-serif is usually cleaner looking if you aren't rendering equations with TeX\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7ad67-bfe3-4bec-b68b-65be279d5ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"air_quality_no2_long.csv\")\n",
    "df_full[\"date.utc\"] = pd.to_datetime(df_full[\"date.utc\"])\n",
    "cities = df_full[\"city\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86094b61-0224-4c12-af05-1643accaaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, sharex=True)  # Initialize a 3x1 grid of plots\n",
    "for i, city in enumerate(cities):\n",
    "    df = df_full.loc[df_full[\"city\"] == city]\n",
    "    ax[i].plot(df[\"date.utc\"], df[\"value\"], linewidth=1.5, alpha=0.8)  # Slightly thicker line with a bit of transparency\n",
    "    ax[i].set_xticks(pd.date_range(start=\"2019-05-08\", end=\"2019-06-22\", freq=\"5D\"))\n",
    "    ax[i].set_ylabel(r\"NO$_2$ concentration ($\\mu$g/L)\")  # Format labels with LaTeX\n",
    "    ax[i].set_title(f\"{city} Air Quality, 2019\")\n",
    "    ax[i].xaxis.set_major_formatter(mdate.DateFormatter(\"%m/%d\"))  # Custom x-tick label format\n",
    "fig.autofmt_xdate()\n",
    "fig.set_size_inches(10, 15)  # Optimal size will depend on the plot, but with time series you often want something pretty wide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598864b-46d1-4dd0-bd18-2be84897d95f",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "Sometimes you want to visualize how a variable changes as a function of two other variables. For that, we need a heatmap, which Seaborn is particularly good at helping us create. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb946ba-583a-4630-9d85-2732a6429ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = sns.load_dataset(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e4a46-313e-4918-b774-1d2286d0349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee40609-4412-48f6-a2c1-5e9f1632aafe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flights = flights.pivot(index=\"month\", columns=\"year\", values=\"passengers\") # Creates a 2d grid to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679052f1-8712-47ae-a877-17c5b1ffa5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727f62b-4cb4-4e7e-bd00-12596b1abe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(flights, cbar_kws={'label': 'Passengers'})\n",
    "ax.set_title(\"Heatmap Flight Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcc6cf-2fb7-410a-9061-a17cacae36ed",
   "metadata": {},
   "source": [
    "## Surface Plots\n",
    "Surface plots come up often enough in optimization settings that it's worth seeing how they work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9026771-b3f3-4351-ab93-e2ae8ae699c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data.\n",
    "x = np.linspace(-8, 8, 100)\n",
    "y = np.linspace(-4, 4, 100)\n",
    "X, Y = np.meshgrid(x, y)  # Turns 1d vectors x and y into 2d grids X and Y\n",
    "Z = X**2 + Y**2  # Defines our values Z = f(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d13448-6766-46d2-b680-368d25dc1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de39b2-9569-48fd-82e7-9db7d7b39b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c945a9-7276-4022-8f67-af96a6868169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b651f-54e7-4616-a4b4-3d4c574315c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f7827-72ce-4131-b1e2-422670d0b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56655bc2-d2ad-4e93-98fc-aa433121b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=\"coolwarm\",\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_zticks(np.arange(0, 90, 20))\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "ax.zaxis.labelpad=-2\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=2, location=\"left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37262863-7cfe-41e8-99b3-c7c7533c4869",
   "metadata": {},
   "source": [
    "## Animations\n",
    "Too many animations in a presentation can be distracting, but every once in a while they can be a really effective (and impressive) way to visualize your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f0e29-ae87-4ce8-b046-a5b9c0abd680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3a04f-eb89-4063-97ff-d074c3938ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Same data as our surface plot above\n",
    "x = np.linspace(-8, 8, 100)\n",
    "y = np.linspace(-4, 4, 100)\n",
    "X, Y = np.meshgrid(x, y)  # Turns 1d vectors x and y into 2d grids X and Y\n",
    "Z = X**2 + Y**2  # Defines our values Z = f(X,Y)\n",
    "\n",
    "def init():\n",
    "    ax.plot_surface(X, Y, Z, cmap=\"coolwarm\",\n",
    "                       linewidth=0, antialiased=False)\n",
    "    ax.set_zticks(np.arange(0, 90, 20))\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.zaxis.labelpad=-2\n",
    "    return fig,\n",
    "\n",
    "def animate(i):\n",
    "    ax.view_init(elev=10., azim=i)\n",
    "    return fig,\n",
    "\n",
    "# Animate\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=360, interval=20, blit=True)\n",
    "# Save\n",
    "anim.save('basic_animation.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e738e2c-5922-4c13-951c-a95de32ec6ff",
   "metadata": {},
   "source": [
    "## Geospatial Visualization\n",
    "Unfortunately, we don't have time in this course to dig deep into geospatial data visualization. It can get very complicated very quickly, so I will simply recommend checking out the [plotly](https://plotly.com/python/maps/) graphing package if you are interested in visualizing geospatial data in Python. Here's an example showing the power of plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480e9d5-1109-41e7-92d7-f44352455e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv\",\n",
    "                   dtype={\"fips\": str})\n",
    "\n",
    "fig = px.choropleth_map(df, geojson=counties, locations='fips', color='unemp',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           range_color=(0, 12),\n",
    "                           map_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'unemp':'unemployment rate'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "plotly.offline.plot(fig, filename='unemployment_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a7e14-dc29-4554-8eeb-2ca6d02a7935",
   "metadata": {},
   "source": [
    "# Breakout: Make a Nice Plot\n",
    "We've now seen how to make lots of different types of plots using matplotlib and seaborn. In this breakout, you'll get a chance to practice these methods on a new dataset. Please do the following:\n",
    "1. Load in a default dataset from seaborn using the [load_dataset](https://seaborn.pydata.org/generated/seaborn.load_dataset.html) functionality.\n",
    "2. Explore the dataset using the pandas methods we have learned about (e.g., `df.head()`, `df.info()`, etc.)\n",
    "3. Make a plot of *something* in the dataset. It could be a scatter plot showing a correlation between two variables, or a time series showing some trend over time, or a heatmap showing how a trend evolves with two different variables.\n",
    "4. Make the plot prettier by updating the plot params.\n",
    "5. Share your plot with your neighbor and explain what your plot is showing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
